{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WD Database for Python\n",
    "\n",
    "The goal is to download the following database: http://vizier.u-strasbg.fr/viz-bin/VizieR?-source=J%2FMNRAS%2F455%2F3413 for use in a machine-learning inspired scheme to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshuapaultan/anaconda/lib/python2.7/site-packages/astroquery/sdss/__init__.py:28: UserWarning: Experimental: SDSS has not yet been refactored to have its API match the rest of astroquery (but it's nearly there).\n",
      "  warnings.warn(\"Experimental: SDSS has not yet been refactored to have its API \"\n"
     ]
    }
   ],
   "source": [
    "#Preamble. Standard packages for to load\n",
    "import astropy\n",
    "from astropy.table import Table, Column, MaskedColumn, vstack \n",
    "import numpy as np\n",
    "from astroquery.vizier import Vizier\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib2\n",
    "# special IPython command to prepare the notebook for matplotlib\n",
    "%matplotlib inline \n",
    "from astroquery.sdss import SDSS\n",
    "from astropy import units as u\n",
    "from astropy import coordinates as coords\n",
    "from astropy.io import fits\n",
    "import astropy.io.ascii as ascii\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "catalog_list_1 = Vizier.find_catalogs('New white dwarf SDSS DR12')\n",
    "catalog_list_2 = Vizier.find_catalogs('J/ApJS/204/5')\n",
    "catalog_list_3 = Vizier.find_catalogs('J/MNRAS/446/4078')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'J/MNRAS/455/3413': u'New white dwarf and subdwarf stars in SDSS DR12 (Kepler+, 2016)'}\n",
      "{u'J/ApJS/204/5': u'SDSS DR7 white dwarf catalog (Kleinman+, 2013)'}\n",
      "{u'J/MNRAS/446/4078': u'New white dwarf stars in SDSS DR10 (Kepler+, 2015)'}\n"
     ]
    }
   ],
   "source": [
    "print({k:v.description for k,v in catalog_list_1.items()})\n",
    "print({k:v.description for k,v in catalog_list_2.items()})\n",
    "print({k:v.description for k,v in catalog_list_3.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Vizier.ROW_LIMIT = -1\n",
    "catalogs_1 = Vizier.get_catalogs(catalog_list_1.keys())\n",
    "catalogs_2 = Vizier.get_catalogs(catalog_list_2.keys())\n",
    "catalogs_3 = Vizier.get_catalogs(catalog_list_3.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(catalogs_1)\n",
    "print(catalogs_2)\n",
    "print(catalogs_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "catalogs = vstack([catalogs_1[0], catalogs_2[0], catalogs_3[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "catalogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This is a way to add coordinates if we need to. I don't think we need to right now.\n",
    "#catalogs['Coordinates'] = coords.SkyCoord(catalogs['_RAJ2000'], catalogs['_DEJ2000'], frame='icrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Here we do clean-up trying to merge those columns which were not properly merged\n",
    "#because they were named different things in different catalogs. These include\n",
    "#SDSS identifiers, a weird underscore for a log(g) parameter, different ways of\n",
    "#specifying spectral type, and different ways of calibrating signal to noise.\n",
    "\n",
    "PMF = catalogs['PMF']\n",
    "\n",
    "for ind,obj in enumerate(PMF):\n",
    "    if type(obj) != np.ma.core.MaskedConstant:\n",
    "        split_PMF = obj.split('-')\n",
    "        catalogs['Plate'][ind] = split_PMF[0]\n",
    "        catalogs['MJD'][ind] = split_PMF[1]\n",
    "        catalogs['Fiber'][ind] = split_PMF[2]\n",
    "        \n",
    "PMJ = catalogs['PMJ']\n",
    "\n",
    "for ind,obj in enumerate(PMJ):\n",
    "    if type(obj) != np.ma.core.MaskedConstant:\n",
    "        split_PMJ = obj.split('-')\n",
    "        catalogs['Plate'][ind] = split_PMJ[0]\n",
    "        catalogs['MJD'][ind] = split_PMJ[1]\n",
    "        catalogs['Fiber'][ind] = split_PMJ[2]\n",
    "\n",
    "log_g_ah = catalogs['log_g_']\n",
    "\n",
    "for ind,obj in enumerate(log_g_ah):\n",
    "    if type(catalogs['logg'][ind]) == np.ma.core.MaskedConstant:\n",
    "        if type(obj) != np.ma.core.MaskedConstant:\n",
    "            catalogs['logg'][ind] = obj\n",
    "            catalogs['e_logg'][ind] = catalogs['e_log_g_'][ind] \n",
    "\n",
    "Types = catalogs['SpType']\n",
    "\n",
    "for ind,obj in enumerate(Types):\n",
    "    if type(catalogs['Type'][ind]) == np.ma.core.MaskedConstant:\n",
    "        if type(obj) != np.ma.core.MaskedConstant:\n",
    "            catalogs['Type'][ind] = obj\n",
    "            \n",
    "SN = catalogs['SNg']\n",
    "\n",
    "for ind,obj in enumerate(SN):\n",
    "    if type(catalogs['S_N'][ind]) == np.ma.core.MaskedConstant:\n",
    "        if type(obj) != np.ma.core.MaskedConstant:\n",
    "            catalogs['S_N'][ind] = obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's select a quality sample of WD spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WD = catalogs[catalogs['Type'] == 'DA']\n",
    "\n",
    "print(\"We start with\", len(WD), \"WDs\")\n",
    "\n",
    "# First, we want to remove systems with NaN's - only found in log g\n",
    "good_WD = WD[np.where(~np.isnan(WD['logg']))]\n",
    "print(\"We removed\", len(WD[np.isnan(WD['logg'])]), \"systems with NaNs\")\n",
    "\n",
    "# Now, we want to remove systems in which the log g was assumed. These all have e_logg=0.0\n",
    "good_WD = good_WD[good_WD['e_logg'] != 0.0]\n",
    "print(\"Number with determined log g\",len(good_WD))\n",
    "\n",
    "# Next, we only want objects with a S/N above 10\n",
    "good_WD = good_WD[good_WD['S_N']>10]\n",
    "print(\"Number with S/N > 10\",len(good_WD))\n",
    "\n",
    "# Next, we want objects with log g uncertainties smaller than, say, 0.2\n",
    "good_WD = good_WD[good_WD['e_logg']<0.2]\n",
    "print(\"Number with log g error less than 0.2\",len(good_WD))\n",
    "\n",
    "# # Let's do the same with T_eff uncertainties - limit to 15% of T_eff\n",
    "# good_WD = good_WD[good_WD['e_Teff']<0.15*good_WD['Teff']]\n",
    "# print(\"Number with Teff uncertainties less than 15%\",len(good_WD))\n",
    "\n",
    "# Print the median Teff error\n",
    "print(\"Median T_eff error:\", np.median(good_WD['e_Teff']))\n",
    "\n",
    "# Print the median log g error\n",
    "print(\"Median log g error:\", np.median(good_WD['e_logg']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def download_data(cat):\n",
    "    directory = 'data/'\n",
    "    cat['file'] = MaskedColumn(length=len(cat),dtype='S32')\n",
    "    for ind,plate in enumerate(cat['Plate']):\n",
    "        try:\n",
    "            spec = SDSS.get_spectra_async(plate=plate, mjd=cat['MJD'][ind], fiberID=WD['Fiber'][ind])\n",
    "            url_of_interest = str(spec[0]).split()[4]\n",
    "            filename = directory+url_of_interest.split('/')[-1]       \n",
    "        except:\n",
    "            print \"No spectra found in database:\", plate, cat['MJD'][ind], cat['Fiber'][ind]\n",
    "            pass\n",
    "        if os.path.exists(filename): \n",
    "            cat['file'][ind] = filename\n",
    "            continue\n",
    "        try:\n",
    "            spec = SDSS.get_spectra(plate=plate, mjd=cat['MJD'][ind], fiberID=cat['Fiber'][ind])\n",
    "            spec[0].writeto(filename)\n",
    "            WD['file'][ind] = filename\n",
    "        except:\n",
    "            print \"Could not download spectra:\", plate, cat['MJD'][ind], cat['Fiber'][ind]\n",
    "            pass  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spec = SDSS.get_spectra(plate=6679,mjd=56401,fiberID=756)\n",
    "\n",
    "print spec[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "download_data(good_WD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_filename(plate,mjd,fiber,wd):\n",
    "    try:\n",
    "        plwd = wd[wd['plate'] == plate]\n",
    "        if len(plwd) == 0: raise Exception()\n",
    "    except Exception:\n",
    "        print 'No plate number'\n",
    "        return ''\n",
    "    try:\n",
    "        mjwd = plwd[plwd['mjd'] == mjd]\n",
    "        if len(mjwd) == 0: raise Exception()\n",
    "    except Exception:\n",
    "        print 'No mjd date'\n",
    "        return ''\n",
    "    try:\n",
    "        fbwd = mjwd[mjwd['fiber'] == fiber]\n",
    "        if len(fbwd) == 0: raise Exception()\n",
    "    except Exception:\n",
    "        print 'No fiber number'\n",
    "        return ''\n",
    "    name = fbwd['file']\n",
    "    return str(name[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_spec(plate,mjd,fiber,wd):\n",
    "    fits_spec = fits.open(get_filename(plate,mjd,fiber,wd))\n",
    "    wavelength = 10**fits_spec[1].data['loglam']\n",
    "    flux = fits_spec[1].data['flux']\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12,4))\n",
    "    ax[0].plot(wavelength, flux)\n",
    "    ax[1].plot(wavelength, flux)\n",
    "    ax[1].set_xlim(3800, 4400)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_spec(337,51997,195,WD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(WD['S_N'])\n",
    "plt.xlabel('Signal to Noise')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training, test, and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Randomly shuffle indices\n",
    "indices = np.arange(len(good_WD))\n",
    "np.random.shuffle(indices)\n",
    "good_shuffle_WD = good_WD[indices]\n",
    "\n",
    "# Determine training, test, and validation sets\n",
    "validation_WD = good_shuffle_WD[0:300]\n",
    "test_WD = good_shuffle_WD[300:600]\n",
    "training_WD = good_shuffle_WD[600:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot up systems in T_eff and log g space to see where they lie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.errorbar(training_WD['logg'], training_WD['Teff'], xerr=training_WD['e_logg'], \n",
    "             yerr=training_WD['e_Teff'], ls='none', fmt='', capsize=0, label='train')\n",
    "\n",
    "plt.errorbar(test_WD['logg'], test_WD['Teff'], xerr=test_WD['e_logg'], \n",
    "             yerr=test_WD['e_Teff'], ls='none', fmt='', capsize=0, label='test')\n",
    "\n",
    "plt.errorbar(validation_WD['logg'], validation_WD['Teff'], xerr=validation_WD['e_logg'], \n",
    "             yerr=validation_WD['e_Teff'], ls='none', fmt='', capsize=0, label='val')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.ylabel(r'T$_{\\rm eff}$')\n",
    "plt.xlabel(r'Log $g$')\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.ylim(5.0e3, 1.0e5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we will look at just the DAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set(good_WD['SpType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DA_good = good_WD[good_WD['SpType']=='DA']\n",
    "\n",
    "print(\"Number of DAs in sample\",len(DA_good))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.errorbar(DA_good['Teff'], DA_good['logg'],yerr=DA_good['e_logg'], \n",
    "             xerr=DA_good['e_Teff'], ls='none', fmt='', capsize=0)\n",
    "\n",
    "\n",
    "plt.xlabel(r'T$_{\\rm eff}$')\n",
    "plt.ylabel(r'Log $g$')\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.xlim(5.0e3, 1.0e5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ascii.write(DA_good, 'DA_good.csv', format='csv', include_names=['_RAJ2000','_DEJ2000','SDSS','S_N','umag','e_umag','gmag','e_gmag','rmag','e_rmag','imag','e_imag','zmag','e_zmag','E_B-V_','pm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ind = []\n",
    "for num,thing in enumerate(good_WD['SpType']):\n",
    "    if 'A' in thing:\n",
    "        ind += [num]\n",
    "\n",
    "All_A = good_WD[ind]\n",
    "print(\"Number of As in sample\",len(All_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "All_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.errorbar(All_A['Teff'], All_A['logg'],yerr=All_A['e_logg'], \n",
    "             xerr=All_A['e_Teff'], ls='none', fmt='', capsize=0, color='red')\n",
    "\n",
    "\n",
    "plt.xlabel(r'T$_{\\rm eff}$')\n",
    "plt.ylabel(r'Log $g$')\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.xlim(5.0e3, 1.0e5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
